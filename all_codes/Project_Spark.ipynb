{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start spark\n",
    "spark = SparkSession.builder.appName(\"Project_Spark\").config(\"spark-master\", \"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#get the data\\nFolder_Path = \\'/Users/KarpKong/VisualStudioCode/CSCI316/Project/Data\\' #The folder to be spliced and its full path, be careful not to include Chinese\\nSaveFile_Path = \\'/Users/KarpKong/VisualStudioCode/CSCI316/Project/MergeData\\'#The file path to save after splicing\\nSaveFile_Name = \\'Data.csv\\'#The file name to save after the merge\\n#Modify the current working directory\\nos.chdir(Folder_Path)\\n#Saves all filenames in this folder into a list\\nfile_list = os.listdir()\\n#Read the first CSV file and include the table header\\ndf = pd.read_csv(Folder_Path +\\'/\\'+ file_list[0])\\n#Write the first read CSV file to the merged file to save\\ndf.to_csv(SaveFile_Path+\\'/\\'+ SaveFile_Name,encoding=\"utf_8_sig\",index=False)\\n#Loop through each CSV file name in the list and append it to the merged file\\nfor i in range(1,len(file_list)):\\n    df = pd.read_csv(Folder_Path + \\'/\\'+ file_list[i])\\n    df.to_csv(SaveFile_Path+\\'/\\'+ SaveFile_Name,encoding=\"utf_8_sig\",index=False, header=False, mode=\\'a+\\')\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data preprocessing.\n",
    "#First, my data exists in 10 blocks, all CSV files, with the same column name and a similar number.\n",
    "#If we want to process all the data, I need to put all the CSV files together into a CSV file with all the data.\n",
    "'''\n",
    "#get the data\n",
    "Folder_Path = '/Users/KarpKong/VisualStudioCode/CSCI316/Project/Data' #The folder to be spliced and its full path, be careful not to include Chinese\n",
    "SaveFile_Path = '/Users/KarpKong/VisualStudioCode/CSCI316/Project/MergeData'#The file path to save after splicing\n",
    "SaveFile_Name = 'Data.csv'#The file name to save after the merge\n",
    "#Modify the current working directory\n",
    "os.chdir(Folder_Path)\n",
    "#Saves all filenames in this folder into a list\n",
    "file_list = os.listdir()\n",
    "#Read the first CSV file and include the table header\n",
    "df = pd.read_csv(Folder_Path +'/'+ file_list[0])\n",
    "#Write the first read CSV file to the merged file to save\n",
    "df.to_csv(SaveFile_Path+'/'+ SaveFile_Name,encoding=\"utf_8_sig\",index=False)\n",
    "#Loop through each CSV file name in the list and append it to the merged file\n",
    "for i in range(1,len(file_list)):\n",
    "    df = pd.read_csv(Folder_Path + '/'+ file_list[i])\n",
    "    df.to_csv(SaveFile_Path+'/'+ SaveFile_Name,encoding=\"utf_8_sig\",index=False, header=False, mode='a+')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|  607|53170|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "|88569|88592|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "|21282|26255|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "|20995|42541|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "|27989|34739|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "|32442|69159|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "|24738|29196|           1|           1|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "| 9904|89061|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "|29926|36578|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "|27815|46246|           1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read the merged Dataset\n",
    "Data = spark.read.csv(\"/Users/KarpKong/VisualStudioCode/CSCI316/Project/MergeData/Data.csv\",inferSchema = 'true',header = 'true')\n",
    "Data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: string (nullable = true)\n",
      " |-- cmp_fname_c2: string (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c2: string (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: string (nullable = true)\n",
      " |-- cmp_bm: string (nullable = true)\n",
      " |-- cmp_by: string (nullable = true)\n",
      " |-- cmp_plz: string (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View data types\n",
    "Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the total number of data\n",
    "num = Data.count()\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5645434"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.filter(Data.cmp_fname_c2 == '?').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5746668"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.filter(Data.cmp_lname_c2 == '?').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cmp_fname_c1: string (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: string (nullable = true)\n",
      " |-- cmp_bm: string (nullable = true)\n",
      " |-- cmp_by: string (nullable = true)\n",
      " |-- cmp_plz: string (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#“id_1” and“id_2” should not be used for prediction\n",
    "#\"cmp_fname_c2\"and 'cmp_lname_c2'Because there are too many missing values, a cannot be a data that can participate in the training, \n",
    "#because the missing value has exceeded 90% of the overall data, so if the average value is used instead, the pollution data will be caused, and the column will be deleted directly.\n",
    "td = Data.drop(\"id_1\",\"id_2\",\"cmp_fname_c2\",'cmp_lname_c2')\n",
    "td.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5734488"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData = td.filter((td.cmp_fname_c1 !=\"?\")&(td.cmp_fname_c1 !=\"?\")&(td.cmp_bd !=\"?\")&(td.cmp_bm !=\"?\")&(td.cmp_by !=\"?\")&(td.cmp_plz !=\"?\"))\n",
    "cleanData.count()\n",
    "#14,644 pieces of data were deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cmp_fname_c1: string (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: string (nullable = true)\n",
      " |-- cmp_bm: string (nullable = true)\n",
      " |-- cmp_by: string (nullable = true)\n",
      " |-- cmp_plz: string (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exported cleanData\n",
    "#cleanData.rdd.map(lambda x:\",\".join(map(str,x))).coalesce(1).saveAsTextFile('cleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reread, change data type\n",
    "cleanData = spark.read.csv(\"/Users/KarpKong/VisualStudioCode/CSCI316/Project/MergeData/cleanData.csv\",inferSchema = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------+------+------+------+-------+--------+\n",
      "|cmp_fname_c1|cmp_lname_c1|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+------------+------------+-------+------+------+------+-------+--------+\n",
      "|         1.0|         1.0|      1|     1|     1|     1|      1|    true|\n",
      "|         1.0|         1.0|      1|     1|     1|     1|      1|    true|\n",
      "|         1.0|         1.0|      1|     1|     1|     1|      1|    true|\n",
      "|         1.0|         1.0|      1|     1|     1|     1|      1|    true|\n",
      "|         1.0|         1.0|      1|     1|     1|     1|      1|    true|\n",
      "+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5734488"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleanData.selectExpr(\"_c0 as cmp_fname_c1\", \"_c1 as cmp_lname_c1\",\"_c2 as cmp_sex\",\"_c3 as cmp_bd\",\"_c4 as cmp_bm\",\"_c5 as cmp_by\",\"_c6 as cmp_plz\",\"_c7 as is_match\")\n",
    "df.show(5)\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Start data preprocessing of adaptive model\n",
    "\n",
    "#Change the target data type from Boolean to String\n",
    "from pyspark.sql.types import StringType\n",
    "cdf = df.withColumn(\"is_match\", df[\"is_match\"].cast(StringType()))#trap！！ lable must be String\n",
    "cdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old split not using\n",
    "#total_data = df['cmp_fname_c1','cmp_lname_c1','cmp_sex','cmp_bd','cmp_bm','cmp_by','cmp_plz']\n",
    "#t = df['cmp_fname_c1','is_match']\n",
    "#total_target = t.drop(t['cmp_fname_c1'])\n",
    "#training_Data,test_Data = total_data.randomSplit([0.7,0.3])\n",
    "#training_target,test_traget = total_target.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encapsulates the data format so that the data exists in the features and labels. \n",
    "#The inputs are one array of vector types. \n",
    "#Label is the target, String type\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator,VectorAssembler,StringIndexer\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = 'is_match', outputCol = 'label')\n",
    "numericCols = ['cmp_fname_c1', 'cmp_lname_c1', 'cmp_sex', 'cmp_bd', 'cmp_bm', 'cmp_by','cmp_plz']\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "stages = []\n",
    "stages +=[label_stringIdx]\n",
    "stages +=[assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "cols = cdf.columns\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(cdf)\n",
    "df1 = pipelineModel.transform(cdf)\n",
    "selectedCols = ['label','features'] + cols\n",
    "df2 = df1.select(selectedCols)\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 4013672\n",
      "Test Dataset Count: 1720816\n"
     ]
    }
   ],
   "source": [
    "#Split train and test Data\n",
    "train, test = df2.randomSplit([0.7, 0.3], seed = 2000)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9997152513691179\n",
      "Test set precision = 0.9998425319004125\n",
      "Test set recall = 0.9998716889179469\n",
      "Test set F-score = 0.9998571101966164\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)#save trained data in lrModel\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "result = lrModel.transform(test)\n",
    "results = result.select(['prediction', 'label'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "cm=metrics.confusionMatrix().toArray()\n",
    "accuracy=(cm[0][0]+cm[1][1])/cm.sum()\n",
    "precision=(cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "recall=(cm[0][0])/(cm[0][0]+cm[0][1])\n",
    "F_score = precision*recall*2/(precision+recall)\n",
    "print('Test set accuracy = '+str(accuracy))\n",
    "print('Test set precision = '+str(precision))\n",
    "print('Test set recall = '+str(recall))\n",
    "print('Test set F-score = '+str(F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "beta = np.sort(lrModel.coefficients)\n",
    "plt.plot(beta)\n",
    "plt.ylabel('Beta Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set areaUnderROC: 0.9996184748492919\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lrModel.summary\n",
    "roc = trainingSummary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('True Positive Rate ')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr = trainingSummary.pr.toPandas()\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+-------+------+------+------+-------+\n",
      "|      cmp_fname_c1|       cmp_lname_c1|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|\n",
      "+------------------+-------------------+-------+------+------+------+-------+\n",
      "|0.0833333333333334|                0.4|      1|     0|     0|     0|      0|\n",
      "|0.0833333333333334|  0.833333333333333|      1|     0|     0|     0|      0|\n",
      "|0.0909090909090909|0.42857142857142894|      1|     0|     0|     0|      0|\n",
      "|0.0909090909090909|                0.5|      1|     0|     0|     0|      0|\n",
      "|0.0909090909090909|                0.6|      1|     0|     0|     0|      0|\n",
      "|0.0909090909090909| 0.7142857142857142|      1|     0|     0|     0|      0|\n",
      "|0.0909090909090909|                0.8|      1|     0|     0|     0|      0|\n",
      "|0.0909090909090909|              0.875|      1|     0|     0|     0|      0|\n",
      "|0.0909090909090909|                1.0|      1|     0|     0|     0|      0|\n",
      "|0.0909090909090909|                1.0|      1|     0|     0|     0|      0|\n",
      "+------------------+-------------------+-------+------+------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "predictions.select('cmp_fname_c1','cmp_lname_c1','cmp_sex','cmp_bd','cmp_bm','cmp_by','cmp_plz').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [1.9671124003179958,6.255132980419243,-6.088472358503153,1.2065381782466824,-0.506904672603796,1.3142524576518801,6.666739546158819]\n",
      "Intercept: -8.004785098323678\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "lrModel = lr.fit(train)\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial coefficients: 2 X 7 CSRMatrix\n",
      "\n",
      "Multinomial intercepts: [2.80454485005525,-2.80454485005525]\n"
     ]
    }
   ],
   "source": [
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(train)\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9999866342479382\n",
      "Test set precision = 0.9999912515528494\n",
      "Test set recall = 0.9999953341424708\n",
      "Test set F-score = 0.9999932928434933\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 10)\n",
    "dtModel = dt.fit(train)\n",
    "\n",
    "result = dtModel.transform(test)\n",
    "results = result.select(['prediction', 'label'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "cm=metrics.confusionMatrix().toArray()\n",
    "accuracy=(cm[0][0]+cm[1][1])/cm.sum()\n",
    "precision=(cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "recall=(cm[0][0])/(cm[0][0]+cm[0][1])\n",
    "F_score = precision*recall*2/(precision+recall)\n",
    "print('Test set accuracy = '+str(accuracy))\n",
    "print('Test set precision = '+str(precision))\n",
    "print('Test set recall = '+str(recall))\n",
    "print('Test set F-score = '+str(F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9999761740941506\n",
      "Test set precision = 0.9999772544353851\n",
      "Test set recall = 0.9999988335356177\n",
      "Test set F-score = 0.9999880438690857\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "rfModel = rf.fit(train)\n",
    "\n",
    "result = rfModel.transform(test)\n",
    "results = result.select(['prediction', 'label'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "cm=metrics.confusionMatrix().toArray()\n",
    "accuracy=(cm[0][0]+cm[1][1])/cm.sum()\n",
    "precision=(cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "recall=(cm[0][0])/(cm[0][0]+cm[0][1])\n",
    "F_score = precision*recall*2/(precision+recall)\n",
    "print('Test set accuracy = '+str(accuracy))\n",
    "print('Test set precision = '+str(precision))\n",
    "print('Test set recall = '+str(recall))\n",
    "print('Test set F-score = '+str(F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9963575420033286\n",
      "Test set precision = 0.9964181953120959\n",
      "Test set recall = 0.9999387606199291\n",
      "Test set F-score = 0.998175373716532\n"
     ]
    }
   ],
   "source": [
    "#NaiveBayes\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "# train the model\n",
    "nbModel = nb.fit(train)\n",
    "\n",
    "result = nbModel.transform(test)\n",
    "results = result.select(['prediction', 'label'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "cm=metrics.confusionMatrix().toArray()\n",
    "accuracy=(cm[0][0]+cm[1][1])/cm.sum()\n",
    "precision=(cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "recall=(cm[0][0])/(cm[0][0]+cm[0][1])\n",
    "F_score = precision*recall*2/(precision+recall)\n",
    "print('Test set accuracy = '+str(accuracy))\n",
    "print('Test set precision = '+str(precision))\n",
    "print('Test set recall = '+str(recall))\n",
    "print('Test set F-score = '+str(F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not using below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanData = MLUtils.loadLibSVMFile(sc,\"/Users/KarpKong/VisualStudioCode/CSCI316/Project/MergeData/cleanData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "from pyspark.mllib.util import MLUtils\n",
    "#Initializing PySpark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"pyspark\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 144.0 failed 1 times, most recent failure: Lost task 2.0 in stage 144.0 (TID 481, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/mllib/util.py\", line 123, in <lambda>\n    parsed = lines.map(lambda l: MLUtils._parse_libsvm_line(l))\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/mllib/util.py\", line 48, in _parse_libsvm_line\n    label = float(items[0])\nValueError: could not convert string to float: '9910,50216,0.111111111111111,?,0.8,?,1,0,1,0,0,False'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/mllib/util.py\", line 123, in <lambda>\n    parsed = lines.map(lambda l: MLUtils._parse_libsvm_line(l))\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/mllib/util.py\", line 48, in _parse_libsvm_line\n    label = float(items[0])\nValueError: could not convert string to float: '9910,50216,0.111111111111111,?,0.8,?,1,0,1,0,0,False'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-227d46523a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadLibSVMFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/Users/KarpKong/VisualStudioCode/CSCI316/Project/MergeData/Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/mllib/util.py\u001b[0m in \u001b[0;36mloadLibSVMFile\u001b[0;34m(sc, path, numFeatures, minPartitions, multiclass)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumFeatures\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mnumFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLabeledPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \"\"\"\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 144.0 failed 1 times, most recent failure: Lost task 2.0 in stage 144.0 (TID 481, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/mllib/util.py\", line 123, in <lambda>\n    parsed = lines.map(lambda l: MLUtils._parse_libsvm_line(l))\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/mllib/util.py\", line 48, in _parse_libsvm_line\n    label = float(items[0])\nValueError: could not convert string to float: '9910,50216,0.111111111111111,?,0.8,?,1,0,1,0,0,False'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/mllib/util.py\", line 123, in <lambda>\n    parsed = lines.map(lambda l: MLUtils._parse_libsvm_line(l))\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/mllib/util.py\", line 48, in _parse_libsvm_line\n    label = float(items[0])\nValueError: could not convert string to float: '9910,50216,0.111111111111111,?,0.8,?,1,0,1,0,0,False'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "DD = MLUtils.loadLibSVMFile(sc,\"/Users/KarpKong/VisualStudioCode/CSCI316/Project/MergeData/Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap to json\n",
    "cleanData.toJSON().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df2.take(10), columns=df2.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test instances and compute test error\n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification tree model:')\n",
    "print(model.toDebugString())\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, \"myModelPath\")\n",
    "sameModel = DecisionTreeModel.load(sc, \"myModelPath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction and test accuracy.\n",
    "predictionAndLabel = test.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / test.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [t[0] for t in df.dtypes if t[1] == 'int']\n",
    "df.select(numeric_features).describe().toPandas().transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
